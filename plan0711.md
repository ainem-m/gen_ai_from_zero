## AIの正体は、人間の“言葉の予測”と同じだった

「ナノ・オーラル合金」のような、もっともらしいウソ。なぜAIはこんなものを生み出してしまうのでしょうか？

その答えを探るために、少しだけ想像してみてください。もし誰かがあなたに、

**「むかしむかし、あるところに？」**

と問いかけたら、どんな言葉を続けたくなりますか？ きっと多くの人が、無意識に**「おじいさんとおばあさんが」**と続けるのではないでしょうか。

実は、今話題の生成AIがやっていることは、この**人間の“言葉の予測”と本質的に同じ**なんです。

私たちは、これまでの人生経験や読書体験から、「この言葉の後には、この言葉が来やすい」というパターンを自然と学んでいます。だから、話の続きを予測できるし、自然な会話ができるのです。

生成AIは、この仕組みを**天文学的な規模**で実行します。

人が読み終えるのに数千年かかると言われるほどの膨大な文章を学習し、「この単語の次には、どの単語が来る確率が最も高いか」という**言葉のつながりのパターン**を、超高速で計算しているのです。

文章を丸暗記しているわけではないので、学習したことのない言葉についても「たぶん、こんな感じの言葉が続くだろう」と予測して、もっともらしい文章を作ってくれます。応用が効く賢い仕組みです。

しかし、ここに「ウソ」が生まれる原因があります。AIはあくまで、**確率的に最も"それっぽい"言葉を選んでいるだけ**。その言葉が、この世界の**事実かどうかを判断しているわけではない**のです。

これが、AIのつくウソの正体。悪意のある「ウソ」ではなく、いわば**人間と似た「言葉の予測」が生み出す副作用**だったのです。

## AIの“知ったかぶり”は、なぜ起きる？

この「言葉の予測」という仕組みが、どうやって具体的な「ウソ」につながるのでしょうか。それには、人間にも少し似た、2つの分かりやすいパターンがあります。

### パターン1：知ったかぶりな予測（事実性のウソ）

これが、例の「ナノ・オーラル合金」の正体です。

例えば、私たちが全く知らない専門分野の話題を振られた時、完全に黙り込むのではなく、知っている関連知識から「それは、たぶん〇〇みたいなことですよね？」と**類推して会話を繋げようとする**ことがありますよね。

AIは、まさにこれを大規模に行っています。「ナノ・オーラル合金」という未知の言葉を聞いた時、AIは「知らない」と答えるのではなく、「"ナノ" "オーラル" "合金" という言葉の組み合わせからすると、きっとこんな性質を持っているに違いない！」と、**学習パターンから最も"ありえそうな"言葉を繋ぎ合わせて、それっぽい説明を創作してしまう**のです。

これは、AIが「事実」を調べているのではなく、あくまで**話の続きとしての“自然さ”**を最優先しているからこそ起こる現象です。

### パターン2：おせっかいな予測（忠実性のウソ）

もう一つのパターンが、「頼んでもいないことまで、勝手にやってしまう」という失敗です。

これも人間と似ています。相手の意図を先回りして、「この話をしているなら、きっとこの情報も知りたいだろう」と、**良かれと思って聞かれていないことまで話してしまう**。そんな経験、ありませんか？

AIも同じです。「この論文を要約して」とお願いしただけなのに、「この技術は、将来的には〇〇にも応用できるでしょう」といった、**元の論文には書かれていない考察**を勝手に付け加えてしまうことがあります。

これも、AIがユーザーの指示に厳密に従うことよりも、「この文脈なら、次に応用例を予測してあげると、より自然で親切だろう」と判断し、**“おせっかい”を焼いてしまった**結果なのです。

このように、AIの「ウソ」は、その仕組みである「言葉の予測」が、時に**知ったかぶり**をし、時に**おせっかい**を焼いてしまうことで発生します。

彼らは悪意を持って私たちを騙そうとしているわけではありません。ただ、ひたすら誠実に、次の言葉を予測し続けているだけなのです。

だからこそ、「ハルシネーションはしないでください」とお願いしても、あまり効果はありません。それは彼らにとって「自然な会話の続きを考えるな」と言っているようなものだからです。

大事なのは、この**AIの“クセ”を理解した上で、うまく付き合っていくこと**なのです。