- AIとは？
  - 例えば将棋AI->棋譜を学習し、次の一手を予測する
  - 天気予報AI->天気の傾向を学習し、次の一手を予測する
  - 小野の回帰方程式->乳歯の大きさと永久歯の大きさの傾向を学習し、乳歯の大きさから永久歯の大きさを予測する
  - 家賃を予測するAI->たとえば部屋の広さは家賃と相関する

- LLMとは
  - 今までの文章の流れから次の一語を予測するAI
  - 大量の文章で学習
  
- LLMの学習に使われたデータとは
  - インターネット上の文章
  - 数カ月かけてAIに教え込む

- LLMが行った学習とは
  - 次に続く言葉の確率分布を計算->学習した文章で、実際に続いていた単語を正解として、正解の確率を上げていく
  - 微分などを使って難しい計算を行っている、膨大な計算資源が必要

- RLHFについて
  - 次に続く言葉の予測だけでは、chatbotとして機能しない
  - 偏見や危険な知識の披露なども行ってしまう
  - 人間が最後に調教している（RLHF）
  
- ハルシネーションの分類
  - 事実性のハルシネーション
    - 事実と異なることを述べてしまうこと
  - 忠実性のハルシネーション
    - 指示と異なることを述べてしまうこと
  
- 事実性のハルシネーションの原因
  - LLMの判断基準は次に続きやすいかどうかのみ
  - 常に全力で推測をしている　それは学習データに含まれていても含まれていなくても同様
  - 習っていないことは知らない、学習した文章より後の出来事は知らない
  - 習ってないことは知らない、機密文書などは知らない
  - マイナーな知識は正解率が低く学習しがち(ロングテールの話)
  - 忠実性のハルシネーションを減らすためのRLHFにより、必要以上に指示に従うようにしてしまった結果のハルシネーション(忖度sycopancy)

- 忠実性のハルシネーションの原因


.	AIの学習方法（大量のテキストデータ）
	- AIは「数千年かかるほど大量の文章」を読み、学習する。
    - 自己教師あり学習->今までの単語から次に繋がる単語はなに？という問題を解いて、正解率が高くなるようなモデルを学習させている
2.	「言葉のつながり」＝パターンを学習
	- AIは文章の丸暗記ではなく、「言葉のつながり」や「流れ」を学習している。
	- 文章の「雰囲気」を覚えているというイメージ。
3.	パターン認識による応用力
	•	学習したパターンを元に、未知の単語でも自然な文章を生成できる。
4.	パターン認識の限界（例外や矛盾の存在）
	•	言葉や文章は常にパターン通りではなく、例外や意外性が存在する。
	•	「一、二、三、と来て、なぜ四？」という厚切りジェイソンの例示（ユーモア）。
5.	パターンに頼るAIの問題点（ハルシネーション）
	•	AIは知らないことでもパターンからそれらしく文章を生成する。
	•	存在しない概念（例：ナノ・オーラル合金）についても矛盾なく説明しようとする。
6.	AIが「知らない」と言わない理由
	•	AIは「知らないことを知らない」と認識するように学習されていない。
	•	むしろ、その場で矛盾なく見栄えのいい文章を作るように訓練されている。
7.	AIの「ウソ」と人間の「ウソ」との違い
	•	AIは意図的にウソをつくのではなく、その場での「最も自然な予測」を行っている。
8.	「ハルシネーションしないで」は無効な指示
	•	AIは事実の真偽を判断せず、あくまで「言葉のつながり」だけを追求しているため、指示そのものが的外れ。

以上のトピック構成に分解できます。