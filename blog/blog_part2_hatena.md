# **AIのつくウソ**に困っている人へ！

この記事は[ゼロから始める生成AIセミナー](https://peatix.com/event/4361342/view)の一部「生成AIのしくみ」のスライド・内容をまとめたものです。`少しマニアックだった`との声をうけ、説明を**ハルシネーションが起きてしまうしくみ**に絞って理解しやすいように**大幅にリライト**しています。  

この記事を読めば、「なぜAIが嘘を付く（ハルシネーション）のか」「ハルシネーションとどう向き合うか」がわかるようになります！

>セミナーを開催できたのは、運営してくださった原嶋先生や、準備期間中に家事育児を引き受けてくれた奥さんのおかげです。ほんとに感謝しかありません。
>そんなわけで、この記事には投げ銭ボタンをつけています。いただいた分は、原嶋先生にこっそりお礼したり、奥さんにちょっといいワインを買ったりする予定です。
>もし`いい記事だったな` `原嶋先生すごい` `奥さん偉っ`と感じていただけたら、応援してもらえるととても嬉しいです。
> <script src="https://codoc.jp/js/cms.js" data-css="rainbow-square" data-usercode="ZT9mEjj5MQ" charset="UTF-8" defer></script>
 <div id="codoc-entry-4IJ6Ilo0AQ" class="codoc-entries" data-without-body="1" data-support-message="👋 応援はこちらから！コーヒー1杯分の投げ銭、大歓迎です☕️「ゲストとして決済」なら会員登録不要です"></div>


## 前回のおさらい

[前回の記事](https://lacramy.hateblo.jp/entry/2025/06/02/180000)では、**ゼロから**…ゼロ知識・ゼロ予算から！はじめる生成AIというテーマで実際にiPhoneにChatGPTをインストールして使い始める方法まで、解説しました。

ポイントをおさらいすると…

```
ここに新規画像










```
- 生成AIは、要約や翻訳、アイデア出し、文章作成など幅広い分野で活躍中。実際の歯科医院での活用例（[院内掲示作成](https://chatgpt.com/share/683a4668-2d10-8008-8122-50556ef6c620)、[マニュアル作成](https://chatgpt.com/share/683a4904-0e18-8008-98e5-fc820bac89c8)、[論文検索](https://chatgpt.com/share/683a4bed-66e4-8008-863d-886cf483983c)など）を具体的に紹介しました。
- 「緻密で精密、ものすごい計算機」ではなく、「人間らしい自然な文章」を作るためのAI、それが **生成AI（ChatGPTやGeminiなど）** です。まさに秘書のような感覚で気軽に仕事や相談を頼めるレベルにまで進化しているのです。
- 今こそ、AIを無料ではじめる「絶好のチャンス」。スマホでのインストール手順も丁寧に画像付きで紹介し、迷わず始められるようサポートしました。


しかし最後に、  
[「ナノ・オーラル合金で補綴はどう変わる？」（クリックで実際にchatGPTに質問できます）](https://chat.openai.com/?prompt=%E3%83%8A%E3%83%8E%E3%83%BB%E3%82%AA%E3%83%BC%E3%83%A9%E3%83%AB%E5%90%88%E9%87%91%E3%81%A7%E8%A3%9C%E7%B6%B4%E3%81%AF%E3%81%A9%E3%81%86%E5%A4%89%E3%82%8F%E3%82%8B%EF%BC%9F)  
という質問に、ChatGPTはなんとスラスラと**架空の材料**について、あたかも実在するかのように、それも**自信満々**に！書き連ねてきました。

他にも、「論文を引用して答えて」と指示したら、存在しない論文をでっち上げられた――なんて経験がある方もいるのではないでしょうか。

実際、2023年にはアメリカで、弁護士が裁判所に提出した書類にChatGPTで生成した6件の**架空の判例**が含まれており、**5,000ドルの罰金**を科されるという事件まで起きています。[^1]

```
ここに画像　ハルシネーションの画像













```

こうした現象こそが、いわゆる**ハルシネーション**です。  
生成AIは、AIならではの便利さがある一方で、時に――いや、しばしば――存在しない情報を「自信満々に」作り上げてしまう、**困った側面**も持っています。

私たち医療従事者にとって、AIの情報を鵜呑みにするのはとても危険なこと。使用者自身が**必ず裏取り**を行う必要があります。  
**今がチャンス！** に並ぶ、2つめのテーマ。

> **信頼せよ、ただし検証せよ**

```
ここに画像
信頼せよの画像










```

今回はこのテーマのもと、  
「なぜAIはこんなウソをつくのか？」「そもそも生成AIはどういう仕組みで動いているのか？」  
そんな疑問に迫りつつ、**ハルシネーション（AIの“嘘つき癖”）とどう向き合えばいいか**を一緒に考えていきましょう！




⸻

電卓や計算機も、最初は“入力された数字や式”に対して“決められたルール”で答えを出すだけ。
電卓に「5+3」と入れたら“8”が返ってくる。
でもそれは、“自分で考えて”出した答えじゃありません。

では、人間と“会話”できるAI――たとえばChatGPTは、どうやって「人間っぽさ」を手に入れたのか？

⸻

データからパターンを“学ぶ”――これがAIの第一歩

ここで**「予測」の話**が出てきます。

回帰方程式のエピソード（乳歯→永久歯）
	•	昭和35年、とある先生が「乳歯の大きさを測ると、将来の永久歯の大きさをだいたい予測できる！」と気づいた。
	•	たくさんの子どもの乳歯と永久歯のサイズを調べて、そこに“関係性”を見つけて線（式）を引く。
	•	この「データに合うように線を引く」「パラメータ（傾き・切片）を調整する」作業、これこそがAIの“学習”の原型。

イメージ図：データの点々、そこに一番近い線を引く

この作業、乳歯だけじゃなく、たとえば「身長」や「体重」など別のデータも加えて式を複雑にすることもできます。
より多くの情報を入れるほど、予測が当たりやすくなる。
これが「多変量回帰」ですが、要は**“つまみ”をいくつも回して、一番当たりやすい答えを探す**イメージ。

⸻

「株価の予測」みたいに複雑なものはどうする？
	•	直線（1本の線）で予測できることもあれば、株価みたいにギザギザ・うねうねした動きも。
	•	こんな複雑な予測を「うまくやりたい！」と思ったとき、人間の脳をヒントにした“ニューロン”の仕組みが登場します。

ニューロンとディープラーニングのイメージ
	•	人間の脳は「ニューロン（神経細胞）」がネットワークになって動いている。
	•	AIも同じく、「たくさんのつまみ＝パラメータ＝重み」を微調整して、複雑なデータにもピタリと当てはまる答えを出せるように進化してきた。

⸻

2章：言葉を「数字」で学ぶ仕組み

“言葉当てゲーム”でAIが育つ！

ここでちょっとクイズ形式にしてみます。

「昔々あるところに、おじいさんとおばあさんがいました。」

「昔々」だけ見て、「このあとにくる単語は？」を当てる。

…この“次の言葉を予測する”ゲームを、AIは膨大な文章で何百万回も繰り返しているのです。

学習のたびに「当てられる確率」が高くなるよう、“つまみ”をグリグリ回して調整する。
これが「学習」と呼ばれるもの。

例：語彙爆発と創発的能力
	•	赤ちゃんが1歳半ごろ急に言葉を覚えるように、AIも大量の言葉を学ぶうちに、ある日突然「翻訳」や「要約」ができるようになる。
	•	この現象は「創発的能力」と呼ばれていて、AIの進化の面白いところ！

⸻

「推理小説」を読むように学ぶAI

推理小説で「犯人は…」の前まで読んで、「次に来る言葉は？」を当てる。

この正解率が上がれば、「小説の内容を理解した！」と言えるはず。

AIはストーリーの流れ・文脈を読み取り、“最もそれらしい言葉”を次々につなげていく。
これが**「会話の自然さ」や「人間っぽさ」**の理由です。

⸻

生成AIは「意味」まで理解してるの？

概念の理解はできるのか？論文から見るAIの限界
	•	研究者たちは「AIは“男”と“女”の違い、叔父と叔母の違いを分かっているのか？」などを検証している。
	•	単語同士の“違い”や“距離”が分かるなら、ある程度「意味」も分かっていると考えられる。
	•	実際に「意味の似た言葉」は“数字の空間”で近くに、「意味の違う言葉」は遠くに位置している。
	•	人間の感覚とかなり近い世界をAIは作っている。

⸻

3章：言葉を“数字の空間”で表す世界

言葉や色、お菓子も「数字の集まり」に！
	•	たとえば「東雲色（しののめいろ）」という色。
	•	赤241、緑144、青114。→この3つの数字で色が決まる。
	•	お菓子も「甘さ」「酸っぱさ」などの数値でイメージできる。

グミ（甘さ0.8、酸っぱさ1.0）、キャンディ（甘さ0.9、酸っぱさ0.4）、チョコ（甘さ1.0、酸っぱさ0.0）、ポテチ（どっちも0.1）

これを「数字の空間」に並べていくと、**「似ている言葉同士が近く」「違う言葉は遠く」**に配置される。

⸻

ひとつの単語＝3,000〜30,000個の数字で表現！
	•	AIの世界では、ひとつの単語が膨大な数字の並びで表されています。
	•	これを「ベクトル」と呼び、「意味空間」での位置を示している。

例：地図の上に点を打つイメージ
	•	「チョコ」と「キャンディ」は近い、「グミ」は少し遠い、「ポテチ」はもっと遠い…という感じ。

⸻

文脈で意味が変わる「セルフアテンション」の力

しょっぱいグミ？文脈を理解するAI

「試合に負けて泣きながら食べたグミは少ししょっぱい」
これ、“グミ”自体は本当は甘いのに、文脈のせいで“しょっぱい”と理解されている。

	•	これができるのは「セルフアテンション」という仕組みのおかげ。
	•	文中の単語同士の関係性をAIが“自動で重み付け”してくれる。

この技術のすごさ
	•	「負けた」と「泣く」と「グミ」という単語のつながりをAIが読み取る
	•	結果、“涙でしょっぱいグミ”という意味までたどり着ける
	•	これが「文脈力」「会話力」の秘密

⸻

葉っぱの話：絵や位置情報もAIが理解？
	•	例：「葉っぱの絵がありました。茎がこうなっています。ここに咲く花はどんなもの？」
	•	AIは「葉っぱ」「茎」の形や位置から、次に来る“花”を予測できる。
	•	文章だけでなく、画像や空間情報もAIは“つながり”として学べる時代。

⸻

4章：AIの「記憶力」や「苦手分野」

AIが覚えていられるのは“文庫本1冊分”まで
	•	AIが会話の文脈を覚えているのは、無料プランなら約4,000字（原稿用紙10枚分くらい）
	•	プロプランなら文庫本1冊分まで
	•	それより前の会話はどんどん“忘れる”

例：「え、さっき言った話もう忘れたの！？」は、ここが原因

⸻

“知識のアップデート”もAIは苦手
	•	無料プランのChatGPTは2023年11月までの知識しか持っていない（記事執筆時点）
	•	最新のニュースや情報、流行りネタは「知らない」ことが多い
	•	それでも最近は、検索機能や追加ツールで“調べてから答える”ことも増えている

⸻

「計算」や「文字数カウント」も実は苦手

10＋20＝30　→このくらいはOK
872×977＝？ →え、無理かも。
「500文字以内で書いて」→実は“だいたい”しかできていない。

	•	AIは「計算が得意そう」に見えて、意外と“細かい計算”や“厳密な文字数”は苦手
	•	“なんとなくこのくらい”で返してくることが多い

⸻

“嘘”をつく理由
	•	AIは「知識を調べている」わけではなく、「今まで学んだ中で一番ありそうな言葉」を選んで返しているだけ
	•	だから間違いも、堂々とウソも「それっぽく」言ってしまう
	•	人間の「カン」に近い

例：「ナノ・オーラル合金って何？」→「それっぽい説明」を堂々とする（でも本当は存在しない）

⸻

5章：AIは“道具”を組み合わせて成長中

最新のAIは「できない」を補うために道具を使う
	•	電卓を使いたいとき→AIが自分で「電卓モード」を呼び出す
	•	検索が必要なとき→「検索モード」に切り替えて情報収集
	•	プログラムを書くとき→「コード実行」や「プログラミング補助」モードが起動

これを「ファンクションコーリング」と呼びます。

⸻

でも、完璧じゃない。使い分けのコツ
	•	AIが「うまく道具を使ってくれる」ときもあれば、使わないままウロウロしてしまうことも
	•	大事なのは、“AIは完璧じゃない”と理解しつつ使うこと！

⸻

6章：まとめ――AIと“うまく付き合う”ために
	•	生成AIは超賢い先生ではなく、一緒に考える相棒です
	•	「叩き台」として使って、自分で仕上げる
	•	ゼロから100までAIにお任せはNG、「一緒に作る」スタンスが一番

⸻

読者への問いかけ・応援メッセージ

ここまで読んでくださりありがとうございます！
「AIのしくみ、なんとなく見えてきたぞ」と思ってもらえたら嬉しいです。

「ここ分からなかった」「もうちょっと知りたい」などあれば、ぜひコメント欄で教えてください。
あなたの疑問が、次回の記事やセミナーのパワーになります！

⸻

次回予告

次回は「プロンプトエンジニアリング――AIに“うまくお願いするコツ”」を解説予定です。
AIと“最高の相棒”になるためのテクニック、一緒に学びましょう！

⸻

⸻

【追伸】もしこの記事が役に立ったら…

コーヒー1杯分の投げ銭で応援してもらえると、記事執筆や次回セミナー開催の大きな励みになります！
（質問や感想もお気軽にどうぞ！）

⸻

---以上ブログ記事

この記事をレビューして欲しい。まだレビューはしないで。これからレビューを担当するペルソナを送ります

[^1] - 2023年、米国ニューヨーク州で実際に起きた事例。弁護士がChatGPTで作成された架空判例を裁判所に提出し、罰金処分となった事件。[ChatGPT生成の“存在しない判例”を使った米弁護士、約72万円の支払いを命じられる - ITmedia NEWS](https://www.itmedia.co.jp/news/articles/2306/27/news106.html)