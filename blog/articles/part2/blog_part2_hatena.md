# **AIのつくウソ**に困っている人へ！

この記事は[ゼロから始める生成AIセミナー](https://peatix.com/event/4361342/view)の一部「生成AIのしくみ」のスライド・内容をまとめたものです。  
`少しマニアックだった`との声をうけ、説明を**ハルシネーションが起きてしまうしくみ**に絞って理解しやすいように**大幅にリライト**しています。  

この記事を読めば、「なぜAIが平気でウソをつくのか？」「その“ハルシネーション”とどう向き合えばいいのか」が、きっと分かるようになるはずです！

> セミナーを開催できたのは、運営してくださった原嶋先生や、準備期間中に家事育児を引き受けてくれた奥さんのおかげです。ほんとに感謝しかありません。
> そんなわけで、この記事には投げ銭ボタンをつけています。いただいた分は、原嶋先生にこっそりお礼したり、奥さんにちょっといいワインを買ったりする予定です。
> もし`いい記事だったな` `原嶋先生すごい` `奥さん偉っ`と感じていただけたら、応援してもらえるととても嬉しいです。
> <script src="https://codoc.jp/js/cms.js" data-css="rainbow-square" data-usercode="ZT9mEjj5MQ" charset="UTF-8" defer></script>
> <div id="codoc-entry-4IJ6Ilo0AQ" class="codoc-entries" data-without-body="1" data-support-message="👋 応援はこちらから！コーヒー1杯分の投げ銭、大歓迎です☕️「ゲストとして決済」なら会員登録不要です"></div>

[:contents]

## 前回のおさらい…AIってすごい！でも…


[前回の記事](https://lacramy.hateblo.jp/entry/2025/06/02/180000)では、**ゼロから**…そう、ゼロ知識・ゼロ予算から！生成AIを始める方法として、実際にiPhoneにChatGPTをインストールするところまでを解説しました。

ポイントをざっくりおさらいすると…

- 生成AIは、要約や翻訳、アイデア出し、文章作成など幅広い分野で活躍中。実際の歯科医院での活用例（[院内掲示作成](https://chatgpt.com/share/683a4668-2d10-8008-8122-50556ef6c620)、[マニュアル作成](https://chatgpt.com/share/683a4904-0e18-8008-98e5-fc820bac89c8)、[論文検索](https://chatgpt.com/share/683a4bed-66e4-8008-863d-886cf483983c)など）を具体的に紹介しました。
- 「緻密で精密、ものすごい計算機」ではなく、**「人間らしい自然な文章を生み出す」**AI、それが **生成AI（ChatGPTやGeminiなど）** です。まさに秘書のような感覚で気軽に仕事や相談を頼めるレベルにまで進化しているのです。
- そして、AIを無料ではじめるなら**今がチャンス!!**。 各社赤字覚悟の無料枠を提供している今、使わない手はありません！


**しかし!** 話はここで終わりませんでした。

[「ナノ・オーラル合金で補綴はどう変わる？」（クリックで実際にchatGPTに質問できます）](https://chat.openai.com/?prompt=%E3%83%8A%E3%83%8E%E3%83%BB%E3%82%AA%E3%83%BC%E3%83%A9%E3%83%AB%E5%90%88%E9%87%91%E3%81%A7%E8%A3%9C%E7%B6%B4%E3%81%AF%E3%81%A9%E3%81%86%E5%A4%89%E3%82%8F%E3%82%8B%EF%BC%9F)  


ChatGPTは、この**架空の材料**について、あたかも実在するかのように、それも<span style="color: #ff5252">**自信満々**</span>に！スラスラとウソを並べ立てました。

他にも、「論文を引用して答えて」と指示したら、存在しない論文をでっち上げられた――なんて経験がある方もいるのではないでしょうか。

実際、2023年にはアメリカで、弁護士が裁判所に提出した書類にChatGPTで生成した6件の**架空の判例**が含まれており、**5,000ドルの罰金**を科されるという事件まで起きています。[^1]

こうした現象こそが、いわゆる**ハルシネーション**です。  
生成AIは、AIならではの便利さがある一方で、時に――いや、しばしば――存在しない情報を「自信満々に」作り上げてしまう、**困った作話癖**も持っています。

私たち医療従事者にとって、AIの情報を鵜呑みにするのはとても危険なこと。使用者自身が**必ず裏取り**を行う必要があります。  
**今がチャンス！** に並ぶ、2つめのテーマがこれです！

> <span style="font-size: 150%">**信頼せよ、ただし検証せよ**</span>



今回はこのテーマのもと、  
「なぜAIはこんなウソをつくのか？」「そもそも生成AIはどういう仕組みで動いているのか？」  
そんな疑問に迫りつつ、**ハルシネーション（…AIの“作話癖”）とどう向き合えばいいか**を一緒に考えていきましょう！




⸻
## 生成AIの学習したこと、行っていること

生成AIが生み出されるとき、**人が読み終えるのに数千年かかる**といわれる程の圧倒的な量の文章[^2]を読ませています。

AIはその文章を使って、文章の中で言葉がどんなふうに「つながるのか」、その「つながりのパターン」[^3]を学習しています。

たとえば、「この言葉のあとには、この言葉がよく来るよね」というような「流れ」を感覚的につかんでいるイメージです。つまり、AIは文章を丸暗記するのではなく、文章の「雰囲気」や「流れ」を覚えているんですね。

丸暗記じゃないからこそ、学習データにない言葉でも「つながりのパターン」を予測して、もっともらしい文章を作ってくれる。応用が効くわけですね。

でもこれ、裏を返せば**「事実と矛盾する文章も作れてしまう」**ということでもあるんです。
だって、世の中の文章がすべてパターン通りなわけないですよね？「一、二、三、と来て、なんで次は四なんだ**Whyyyyyy Japanese peopleeeeeeeeeeeee！！！！！**」って厚切りジェイソンも言ってました（笑）。
脱線したっぽいけど、えーと、つまり、文章や言葉には、パターンだけでは割り切れない例外や、意外性があるということなんです。

実際に、AIがパターンだけを使って作った文章は、よく読むとちょっと違和感があることもわかっています。[^4]

だから、例の「ナノ・オーラル合金」みたいに、この世に存在しないことを聞かれても、「知りません」とは言わない。「知りません」とはなかなか言わない。AIは知らないことに対して「知らない」と答えるように学習しているわけではないからです。その代わり、「うーん、ナノレベルの技術が使われている歯科合金ということは…こんな物性があるんですかね！」ってなノリで、それっぽい単語を並べて、矛盾がないように見える見栄えのいい文章を作ってしまいます。なぜならそう訓練されているから。

つまり、AIが生成した「事実と異なる文章」は、人間がつくウソとは少し違います。AIにとっては、それがその場で可能な限り「誠実な予測の結果」なのです。AIは知識を検索しているのではなく、あくまで「自然につながりやすい言葉」を必死に紡いでいるだけ。[^5]

よく「AIに『ハルシネーションをしないでください』と指示するプロンプトが話題になりますが、これはあまり効果的ではありません。なぜならAIはいつも、ただ「次に続きやすい言葉」を全力で予測しているだけだからです。AIは文章が事実かどうかを判断して言葉を選んでいるわけではなく、純粋に「言葉のつながりやすさ」だけを見ているのです。

⸻
<details>
<summary>セミナーの超抜粋（クリックで開閉）</summary>
少しマニアックだったかな…と思った部分を超抜粋で。
需要がありそうならもっと詳しくして番外編として公開します

## 生成AIは「意味」まで理解してるの？

概念の理解はできるのか？論文から見るAIの限界
	•	研究者たちは「AIは“男”と“女”の違い、叔父と叔母の違いを分かっているのか？」などを検証している。
	•	単語同士の“違い”や“距離”が分かるなら、ある程度「意味」も分かっていると考えられる。
	•	実際に「意味の似た言葉」は“数字の空間”で近くに、「意味の違う言葉」は遠くに位置している。
	•	人間の感覚とかなり近い世界をAIは作っている。


## 言葉を“数字の空間”で表す世界

言葉や色、お菓子も「数字の集まり」に！
	•	たとえば「東雲色（しののめいろ）」という色。
	•	赤241、緑144、青114。→この3つの数字で色が決まる。
	•	お菓子も「甘さ」「酸っぱさ」などの数値でイメージできる。

グミ（甘さ0.8、酸っぱさ1.0）、キャンディ（甘さ0.9、酸っぱさ0.4）、チョコ（甘さ1.0、酸っぱさ0.0）、ポテチ（どっちも0.1）

これを「数字の空間」に並べていくと、**「似ている言葉同士が近く」「違う言葉は遠く」**に配置される。

ひとつの単語＝3,000〜30,000個の数字で表現！
	•	AIの世界では、ひとつの単語が膨大な数字の並びで表されています。
	•	これを「ベクトル」と呼び、「意味空間」での位置を示している。

例：地図の上に点を打つイメージ
	•	「チョコ」と「キャンディ」は近い、「グミ」は少し遠い、「ポテチ」はもっと遠い…という感じ。


## 文脈で意味が変わる「セルフアテンション」の力

### しょっぱいグミ？文脈を理解するAI

「試合に負けて泣きながら食べたグミは少ししょっぱい」
これ、“グミ”自体は本当は甘いのに、文脈のせいで“しょっぱい”と理解されている。

	•	これができるのは「セルフアテンション」という仕組みのおかげ。
	•	文中の単語同士の関係性をAIが“自動で重み付け”してくれる。

### この技術のすごさ
	•	「負けた」と「泣く」と「グミ」という単語のつながりをAIが読み取る
	•	結果、“涙でしょっぱいグミ”という意味までたどり着ける
	•	これが「文脈力」「会話力」の秘密

### 葉っぱの話：絵や位置情報もAIが理解？
	•	例：「葉っぱの絵がありました。茎がこうなっています。ここに咲く花はどんなもの？」
	•	AIは「葉っぱ」「茎」の形や位置から、次に来る“花”を予測できる。
	•	文章だけでなく、画像や空間情報もAIは“つながり”として学べる時代。


## AIの「記憶力」や「苦手分野」

### AIが覚えていられるのは“文庫本1冊分”まで
	•	AIが会話の文脈を覚えているのは、無料プランなら約4,000字（原稿用紙10枚分くらい）
	•	プロプランなら文庫本1冊分まで
	•	それより前の会話はどんどん“忘れる”

例：「え、さっき言った話もう忘れたの！？」は、ここが原因


### “知識のアップデート”もAIは苦手
	•	無料プランのChatGPTは2023年11月までの知識しか持っていない（記事執筆時点）
	•	最新のニュースや情報、流行りネタは「知らない」ことが多い
	•	それでも最近は、検索機能や追加ツールで“調べてから答える”ことも増えている


### 「計算」や「文字数カウント」も実は苦手

10＋20＝30　→このくらいはOK
872×977＝？ →え、無理かも。
「500文字以内で書いて」→実は“だいたい”しかできていない。

	•	AIは「計算が得意そう」に見えて、意外と“細かい計算”や“厳密な文字数”は苦手
	•	“なんとなくこのくらい”で返してくることが多い


### “嘘”をつく理由
	•	AIは「知識を調べている」わけではなく、「今まで学んだ中で一番ありそうな言葉」を選んで返しているだけ
	•	だから間違いも、堂々とウソも「それっぽく」言ってしまう
	•	人間の「カン」に近い

例：「ナノ・オーラル合金って何？」→「それっぽい説明」を堂々とする（でも本当は存在しない）


### AIは“道具”を組み合わせて成長中

最新のAIは「できない」を補うために道具を使う
	•	電卓を使いたいとき→AIが自分で「電卓モード」を呼び出す
	•	検索が必要なとき→「検索モード」に切り替えて情報収集
	•	プログラムを書くとき→「コード実行」や「プログラミング補助」モードが起動

これを「ファンクションコーリング」と呼びます。

でも、完璧じゃない。使い分けのコツ
	•	AIが「うまく道具を使ってくれる」ときもあれば、使わないままウロウロしてしまうことも
	•	大事なのは、“AIは完璧じゃない”と理解しつつ使うこと！


### まとめ――AIと“うまく付き合う”ために
	•	生成AIは超賢い先生ではなく、一緒に考える相棒です
	•	「叩き台」として使って、自分で仕上げる
	•	ゼロから100までAIにお任せはNG、「一緒に作る」スタンスが一番


</details>
⸻


ここまで読んでくださりありがとうございます！
「AIのしくみ、なんとなく見えてきたぞ」と思ってもらえたら嬉しいです。

「ここ分からなかった」「もうちょっと知りたい」などあれば、ぜひコメント欄で教えてください。
あなたの疑問が、次回の記事やセミナーのパワーになります！


次回予告

次回は「プロンプトエンジニアリング――AIに“うまくお願いするコツ”」を解説予定です。
AIと“最高の相棒”になるためのテクニック、一緒に学びましょう！



【追伸】もしこの記事が役に立ったら…

コーヒー1杯分の投げ銭で応援してもらえると、記事執筆や次回セミナー開催の大きな励みになります！
（質問や感想もお気軽にどうぞ！）

⸻

---以上ブログ記事

この記事をレビューして欲しい。まだレビューはしないで。これからレビューを担当するペルソナを送ります

[^1] - 2023年、米国ニューヨーク州で実際に起きた事例。弁護士がChatGPTで作成された架空判例を裁判所に提出し、罰金処分となった事件。[ChatGPT生成の“存在しない判例”を使った米弁護士、約72万円の支払いを命じられる - ITmedia NEWS](https://www.itmedia.co.jp/news/articles/2306/27/news106.html)
[^2] - 数千年かかる文章
[^3] - 次トークン予測のこと
[^4] - 温度を下げたときの文章が不自然である例を示す
[^5] - function callingといって、最近のchatbotには検索機能もついています